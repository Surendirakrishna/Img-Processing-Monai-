{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image Classification with monai"
      ],
      "metadata": {
        "id": "QUUJxjz1HC-h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Datasets"
      ],
      "metadata": {
        "id": "iv7o5wwUHNhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3MH4wBLoGFsj"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz\n",
        "# unzip the '.tar.gz' file to the current directory\n",
        "import tarfile\n",
        "datafile = tarfile.open(\"MedNIST.tar.gz\")\n",
        "datafile.extractall()\n",
        "datafile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Monai\n"
      ],
      "metadata": {
        "id": "TfG1aCxZHpDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"monai-weekly[gdown, nibabel, tqdm, itk]\"\n",
        "import os\n",
        "import shutil\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandFlip,\n",
        "    RandRotate,\n",
        "    RandZoom,\n",
        "    ScaleIntensity,\n",
        "    ToTensor,\n",
        ")\n",
        "from monai.data import Dataset, DataLoader\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "print_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Wt3h6-iEHq_R",
        "outputId": "f3c10237-ee7d-4d9e-dcb6-f8a6c1c5cb67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.0/28.0 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/28.4 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMONAI version: 1.5.dev2443\n",
            "Numpy version: 1.26.4\n",
            "Pytorch version: 2.5.0+cu121\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
            "MONAI rev id: d508ba780862a6459326c812e09188838c25bdc5\n",
            "MONAI __file__: /usr/local/lib/python3.10/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "ITK version: 5.4.0\n",
            "Nibabel version: 5.2.1\n",
            "scikit-image version: 0.24.0\n",
            "scipy version: 1.13.1\n",
            "Pillow version: 10.4.0\n",
            "Tensorboard version: 2.17.0\n",
            "gdown version: 5.2.0\n",
            "TorchVision version: 0.20.0+cu121\n",
            "tqdm version: 4.66.5\n",
            "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "psutil version: 5.9.5\n",
            "pandas version: 2.2.2\n",
            "einops version: 0.8.0\n",
            "transformers version: 4.44.2\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read image filenames from the dataset folders"
      ],
      "metadata": {
        "id": "l2hNjAbRIM8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './MedNIST/'\n",
        "class_names = sorted([x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x))])\n",
        "num_class = len(class_names)\n",
        "image_files = [[os.path.join(data_dir, class_name, x)\n",
        "                for x in os.listdir(os.path.join(data_dir, class_name))]\n",
        "               for class_name in class_names]\n",
        "image_file_list = []\n",
        "image_label_list = []\n",
        "for i, class_name in enumerate(class_names):\n",
        "    image_file_list.extend(image_files[i])\n",
        "    image_label_list.extend([i] * len(image_files[i]))\n",
        "num_total = len(image_label_list)\n",
        "image_width, image_height = Image.open(image_file_list[0]).size\n",
        "\n",
        "print('Total image count:', num_total)\n",
        "print(\"Image dimensions:\", image_width, \"x\", image_height)\n",
        "print(\"Label names:\", class_names)\n",
        "print(\"Label counts:\", [len(image_files[i]) for i in range(num_class)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUvFqqblH6j1",
        "outputId": "9016f26f-dab9-42e6-bd80-90f9afd680c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total image count: 58954\n",
            "Image dimensions: 64 x 64\n",
            "Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
            "Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare training, validation and test data lists"
      ],
      "metadata": {
        "id": "cH9c2C9UIfOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_frac, test_frac = 0.1, 0.1\n",
        "trainX, trainY = [], []\n",
        "valX, valY = [], []\n",
        "testX, testY = [], []\n",
        "\n",
        "for i in range(num_total):\n",
        "    rann = np.random.random()\n",
        "    if rann < valid_frac:\n",
        "        valX.append(image_file_list[i])\n",
        "        valY.append(image_label_list[i])\n",
        "    elif rann < test_frac + valid_frac:\n",
        "        testX.append(image_file_list[i])\n",
        "        testY.append(image_label_list[i])\n",
        "    else:\n",
        "        trainX.append(image_file_list[i])\n",
        "        trainY.append(image_label_list[i])\n",
        "\n",
        "print(\"Training count =\",len(trainX),\"Validation count =\", len(valX), \"Test count =\",len(testX))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMcG6U6_IhlG",
        "outputId": "58dcf29c-6498-4019-ae14-2fb44b32a5bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training count = 47161 Validation count = 5801 Test count = 5992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define MONAI transforms, Dataset and Dataloader to pre-process data"
      ],
      "metadata": {
        "id": "9DLbN1a-JneR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose([\n",
        "    LoadImage(image_only=True),\n",
        "    EnsureChannelFirst(),\n",
        "    ScaleIntensity(),\n",
        "    RandRotate(range_x=15, prob=0.5, keep_size=True),\n",
        "    RandFlip(spatial_axis=0, prob=0.5),\n",
        "    RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5, keep_size=True),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "val_transforms = Compose([\n",
        "    LoadImage(image_only=True),\n",
        "    EnsureChannelFirst(),\n",
        "    ScaleIntensity(),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "act = Activations(softmax=True)\n",
        "to_onehot = AsDiscrete(to_onehot=num_class)"
      ],
      "metadata": {
        "id": "iYGsS_GZJrlP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedNISTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, image_files, labels, transforms):\n",
        "        self.image_files = image_files\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.image_files[index]), self.labels[index]\n",
        "\n",
        "train_ds = MedNISTDataset(trainX, trainY, train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=300, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = MedNISTDataset(valX, valY, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=300, num_workers=2)\n",
        "\n",
        "test_ds = MedNISTDataset(testX, testY, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=300, num_workers=2)"
      ],
      "metadata": {
        "id": "o8Nb3RUtJ8Y8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implies GPU (Change Your Runtime Setting into CPU to T4 GPU from Google colob)"
      ],
      "metadata": {
        "id": "5a7mfJtuKPjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "model = DenseNet121(\n",
        "    spatial_dims=2,\n",
        "    in_channels=1,\n",
        "    out_channels=num_class\n",
        ").to(device)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
        "epoch_num = 4\n",
        "val_interval = 1"
      ],
      "metadata": {
        "id": "bRnlNgxLKO2d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Traing"
      ],
      "metadata": {
        "id": "R9aX1aCoNYjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = list()\n",
        "auc_metric = ROCAUCMetric()\n",
        "metric_values = list()\n",
        "for epoch in range(epoch_num):\n",
        "    print('-' * 10)\n",
        "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, train_loss: {loss.item():.4f}\")\n",
        "        epoch_len = len(train_ds) // train_loader.batch_size\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
        "            y = torch.tensor([], dtype=torch.long, device=device)\n",
        "            for val_data in val_loader:\n",
        "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
        "                y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
        "                y = torch.cat([y, val_labels], dim=0)\n",
        "            y_onehot = [to_onehot(i) for i in y]\n",
        "            y_pred_act = [act(i) for i in y_pred]\n",
        "            auc_metric(y_pred_act, y_onehot)\n",
        "            auc_result = auc_metric.aggregate()\n",
        "            auc_metric.reset()\n",
        "            del y_pred_act, y_onehot\n",
        "            metric_values.append(auc_result)\n",
        "            acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
        "            acc_metric = acc_value.sum().item() / len(acc_value)\n",
        "            if acc_metric > best_metric:\n",
        "                best_metric = acc_metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), 'best_metric_model.pth')\n",
        "                print('saved new best metric model')\n",
        "            print(f\"current epoch: {epoch + 1} current AUC: {auc_result:.4f}\"\n",
        "                  f\" current accuracy: {acc_metric:.4f} best AUC: {best_metric:.4f}\"\n",
        "                  f\" at epoch: {best_metric_epoch}\")\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")"
      ],
      "metadata": {
        "id": "T6gpWdXvNb0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e469e58-fcdd-4b3e-b194-31230a7efb09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/4\n",
            "1/157, train_loss: 1.8131\n",
            "2/157, train_loss: 1.7903\n",
            "3/157, train_loss: 1.7893\n",
            "4/157, train_loss: 1.7518\n",
            "5/157, train_loss: 1.7049\n",
            "6/157, train_loss: 1.6900\n",
            "7/157, train_loss: 1.6619\n",
            "8/157, train_loss: 1.6167\n",
            "9/157, train_loss: 1.6293\n",
            "10/157, train_loss: 1.5865\n",
            "11/157, train_loss: 1.5864\n",
            "12/157, train_loss: 1.5651\n",
            "13/157, train_loss: 1.5344\n",
            "14/157, train_loss: 1.5530\n",
            "15/157, train_loss: 1.5106\n",
            "16/157, train_loss: 1.4855\n",
            "17/157, train_loss: 1.4848\n",
            "18/157, train_loss: 1.4415\n",
            "19/157, train_loss: 1.3885\n",
            "20/157, train_loss: 1.3787\n",
            "21/157, train_loss: 1.3842\n",
            "22/157, train_loss: 1.3633\n",
            "23/157, train_loss: 1.3421\n",
            "24/157, train_loss: 1.2806\n",
            "25/157, train_loss: 1.2886\n",
            "26/157, train_loss: 1.2680\n",
            "27/157, train_loss: 1.2406\n",
            "28/157, train_loss: 1.2350\n",
            "29/157, train_loss: 1.2343\n",
            "30/157, train_loss: 1.2091\n",
            "31/157, train_loss: 1.1563\n",
            "32/157, train_loss: 1.1949\n",
            "33/157, train_loss: 1.1684\n",
            "34/157, train_loss: 1.1167\n",
            "35/157, train_loss: 1.1095\n",
            "36/157, train_loss: 1.1190\n",
            "37/157, train_loss: 1.0708\n",
            "38/157, train_loss: 1.0807\n",
            "39/157, train_loss: 1.0939\n",
            "40/157, train_loss: 1.0726\n",
            "41/157, train_loss: 1.0163\n",
            "42/157, train_loss: 1.0296\n",
            "43/157, train_loss: 0.9895\n",
            "44/157, train_loss: 1.0099\n",
            "45/157, train_loss: 0.9881\n",
            "46/157, train_loss: 0.9820\n",
            "47/157, train_loss: 0.9668\n",
            "48/157, train_loss: 0.9370\n",
            "49/157, train_loss: 0.9795\n",
            "50/157, train_loss: 0.9221\n",
            "51/157, train_loss: 0.8971\n",
            "52/157, train_loss: 0.9054\n",
            "53/157, train_loss: 0.8635\n",
            "54/157, train_loss: 0.9174\n",
            "55/157, train_loss: 0.8632\n",
            "56/157, train_loss: 0.9234\n",
            "57/157, train_loss: 0.8936\n",
            "58/157, train_loss: 0.8246\n",
            "59/157, train_loss: 0.8508\n",
            "60/157, train_loss: 0.8150\n",
            "61/157, train_loss: 0.8371\n",
            "62/157, train_loss: 0.7933\n",
            "63/157, train_loss: 0.7873\n",
            "64/157, train_loss: 0.8229\n",
            "65/157, train_loss: 0.7607\n",
            "66/157, train_loss: 0.7893\n",
            "67/157, train_loss: 0.7398\n",
            "68/157, train_loss: 0.7611\n",
            "69/157, train_loss: 0.7981\n",
            "70/157, train_loss: 0.7490\n",
            "71/157, train_loss: 0.7211\n",
            "72/157, train_loss: 0.7072\n",
            "73/157, train_loss: 0.6957\n",
            "74/157, train_loss: 0.6990\n",
            "75/157, train_loss: 0.6769\n",
            "76/157, train_loss: 0.6751\n",
            "77/157, train_loss: 0.6900\n",
            "78/157, train_loss: 0.6568\n",
            "79/157, train_loss: 0.6859\n",
            "80/157, train_loss: 0.7062\n",
            "81/157, train_loss: 0.6195\n",
            "82/157, train_loss: 0.6631\n",
            "83/157, train_loss: 0.6126\n",
            "84/157, train_loss: 0.6154\n",
            "85/157, train_loss: 0.5920\n",
            "86/157, train_loss: 0.6774\n",
            "87/157, train_loss: 0.5881\n",
            "88/157, train_loss: 0.6030\n",
            "89/157, train_loss: 0.5992\n",
            "90/157, train_loss: 0.6515\n",
            "91/157, train_loss: 0.5856\n",
            "92/157, train_loss: 0.5594\n",
            "93/157, train_loss: 0.5306\n",
            "94/157, train_loss: 0.5440\n",
            "95/157, train_loss: 0.5235\n",
            "96/157, train_loss: 0.6005\n",
            "97/157, train_loss: 0.5310\n",
            "98/157, train_loss: 0.5459\n",
            "99/157, train_loss: 0.5682\n",
            "100/157, train_loss: 0.5226\n",
            "101/157, train_loss: 0.5231\n",
            "102/157, train_loss: 0.5160\n",
            "103/157, train_loss: 0.5571\n",
            "104/157, train_loss: 0.4961\n",
            "105/157, train_loss: 0.5164\n",
            "106/157, train_loss: 0.4982\n",
            "107/157, train_loss: 0.4594\n",
            "108/157, train_loss: 0.4665\n",
            "109/157, train_loss: 0.4899\n",
            "110/157, train_loss: 0.5052\n",
            "111/157, train_loss: 0.5063\n",
            "112/157, train_loss: 0.5269\n",
            "113/157, train_loss: 0.4750\n",
            "114/157, train_loss: 0.4476\n",
            "115/157, train_loss: 0.4394\n",
            "116/157, train_loss: 0.4470\n",
            "117/157, train_loss: 0.4656\n",
            "118/157, train_loss: 0.4747\n",
            "119/157, train_loss: 0.4547\n",
            "120/157, train_loss: 0.4335\n",
            "121/157, train_loss: 0.4403\n",
            "122/157, train_loss: 0.4184\n",
            "123/157, train_loss: 0.4208\n",
            "124/157, train_loss: 0.3884\n",
            "125/157, train_loss: 0.3946\n",
            "126/157, train_loss: 0.4102\n",
            "127/157, train_loss: 0.4013\n",
            "128/157, train_loss: 0.3857\n",
            "129/157, train_loss: 0.3751\n",
            "130/157, train_loss: 0.4161\n",
            "131/157, train_loss: 0.4089\n",
            "132/157, train_loss: 0.4025\n",
            "133/157, train_loss: 0.3625\n",
            "134/157, train_loss: 0.3316\n",
            "135/157, train_loss: 0.3930\n",
            "136/157, train_loss: 0.3711\n",
            "137/157, train_loss: 0.4143\n",
            "138/157, train_loss: 0.3904\n",
            "139/157, train_loss: 0.3559\n",
            "140/157, train_loss: 0.3068\n",
            "141/157, train_loss: 0.3562\n",
            "142/157, train_loss: 0.3300\n",
            "143/157, train_loss: 0.3356\n",
            "144/157, train_loss: 0.3446\n",
            "145/157, train_loss: 0.3352\n",
            "146/157, train_loss: 0.3461\n",
            "147/157, train_loss: 0.3794\n",
            "148/157, train_loss: 0.3326\n",
            "149/157, train_loss: 0.3838\n",
            "150/157, train_loss: 0.2933\n",
            "151/157, train_loss: 0.3267\n",
            "152/157, train_loss: 0.3008\n",
            "153/157, train_loss: 0.3084\n",
            "154/157, train_loss: 0.3269\n",
            "155/157, train_loss: 0.3398\n",
            "156/157, train_loss: 0.3198\n",
            "157/157, train_loss: 0.2988\n",
            "158/157, train_loss: 0.3695\n",
            "epoch 1 average loss: 0.7884\n",
            "saved new best metric model\n",
            "current epoch: 1 current AUC: 0.9974 current accuracy: 0.9631 best AUC: 0.9631 at epoch: 1\n",
            "----------\n",
            "epoch 2/4\n",
            "1/157, train_loss: 0.3283\n",
            "2/157, train_loss: 0.2900\n",
            "3/157, train_loss: 0.3705\n",
            "4/157, train_loss: 0.3070\n",
            "5/157, train_loss: 0.3007\n",
            "6/157, train_loss: 0.2799\n",
            "7/157, train_loss: 0.3274\n",
            "8/157, train_loss: 0.2759\n",
            "9/157, train_loss: 0.2977\n",
            "10/157, train_loss: 0.3380\n",
            "11/157, train_loss: 0.2465\n",
            "12/157, train_loss: 0.2793\n",
            "13/157, train_loss: 0.2860\n",
            "14/157, train_loss: 0.2914\n",
            "15/157, train_loss: 0.2630\n",
            "16/157, train_loss: 0.2679\n",
            "17/157, train_loss: 0.2391\n",
            "18/157, train_loss: 0.2622\n",
            "19/157, train_loss: 0.2437\n",
            "20/157, train_loss: 0.2565\n",
            "21/157, train_loss: 0.2423\n",
            "22/157, train_loss: 0.2961\n",
            "23/157, train_loss: 0.2819\n",
            "24/157, train_loss: 0.2979\n",
            "25/157, train_loss: 0.2626\n",
            "26/157, train_loss: 0.2309\n",
            "27/157, train_loss: 0.2540\n",
            "28/157, train_loss: 0.2241\n",
            "29/157, train_loss: 0.2797\n",
            "30/157, train_loss: 0.2936\n",
            "31/157, train_loss: 0.2717\n",
            "32/157, train_loss: 0.2479\n",
            "33/157, train_loss: 0.2667\n",
            "34/157, train_loss: 0.2244\n",
            "35/157, train_loss: 0.2199\n",
            "36/157, train_loss: 0.2423\n",
            "37/157, train_loss: 0.2472\n",
            "38/157, train_loss: 0.2244\n",
            "39/157, train_loss: 0.2364\n",
            "40/157, train_loss: 0.2194\n",
            "41/157, train_loss: 0.2312\n",
            "42/157, train_loss: 0.2395\n",
            "43/157, train_loss: 0.2385\n",
            "44/157, train_loss: 0.2002\n",
            "45/157, train_loss: 0.2344\n",
            "46/157, train_loss: 0.2208\n",
            "47/157, train_loss: 0.2226\n",
            "48/157, train_loss: 0.2022\n",
            "49/157, train_loss: 0.2017\n",
            "50/157, train_loss: 0.1741\n",
            "51/157, train_loss: 0.2705\n",
            "52/157, train_loss: 0.2335\n",
            "53/157, train_loss: 0.1920\n",
            "54/157, train_loss: 0.1945\n",
            "55/157, train_loss: 0.2184\n",
            "56/157, train_loss: 0.2057\n",
            "57/157, train_loss: 0.2334\n",
            "58/157, train_loss: 0.1895\n",
            "59/157, train_loss: 0.2152\n",
            "60/157, train_loss: 0.2174\n",
            "61/157, train_loss: 0.2240\n",
            "62/157, train_loss: 0.2208\n",
            "63/157, train_loss: 0.2248\n",
            "64/157, train_loss: 0.1845\n",
            "65/157, train_loss: 0.2180\n",
            "66/157, train_loss: 0.1853\n",
            "67/157, train_loss: 0.2145\n",
            "68/157, train_loss: 0.1965\n",
            "69/157, train_loss: 0.2400\n",
            "70/157, train_loss: 0.1649\n",
            "71/157, train_loss: 0.2175\n",
            "72/157, train_loss: 0.1961\n",
            "73/157, train_loss: 0.2129\n",
            "74/157, train_loss: 0.2188\n",
            "75/157, train_loss: 0.1868\n",
            "76/157, train_loss: 0.1928\n",
            "77/157, train_loss: 0.2029\n",
            "78/157, train_loss: 0.1895\n",
            "79/157, train_loss: 0.1871\n",
            "80/157, train_loss: 0.1868\n",
            "81/157, train_loss: 0.2098\n",
            "82/157, train_loss: 0.2191\n",
            "83/157, train_loss: 0.1819\n",
            "84/157, train_loss: 0.2383\n",
            "85/157, train_loss: 0.1612\n",
            "86/157, train_loss: 0.1515\n",
            "87/157, train_loss: 0.1779\n",
            "88/157, train_loss: 0.1853\n",
            "89/157, train_loss: 0.1458\n",
            "90/157, train_loss: 0.1756\n",
            "91/157, train_loss: 0.1617\n",
            "92/157, train_loss: 0.1784\n",
            "93/157, train_loss: 0.1751\n",
            "94/157, train_loss: 0.1881\n",
            "95/157, train_loss: 0.1521\n",
            "96/157, train_loss: 0.1940\n",
            "97/157, train_loss: 0.1467\n",
            "98/157, train_loss: 0.1835\n",
            "99/157, train_loss: 0.1510\n",
            "100/157, train_loss: 0.2267\n",
            "101/157, train_loss: 0.1520\n",
            "102/157, train_loss: 0.1782\n",
            "103/157, train_loss: 0.1589\n",
            "104/157, train_loss: 0.1513\n",
            "105/157, train_loss: 0.1810\n",
            "106/157, train_loss: 0.1590\n",
            "107/157, train_loss: 0.1615\n",
            "108/157, train_loss: 0.1728\n",
            "109/157, train_loss: 0.1745\n",
            "110/157, train_loss: 0.1655\n",
            "111/157, train_loss: 0.1482\n",
            "112/157, train_loss: 0.1498\n",
            "113/157, train_loss: 0.1540\n",
            "114/157, train_loss: 0.1725\n",
            "115/157, train_loss: 0.1618\n",
            "116/157, train_loss: 0.1672\n",
            "117/157, train_loss: 0.1157\n",
            "118/157, train_loss: 0.1397\n",
            "119/157, train_loss: 0.1626\n",
            "120/157, train_loss: 0.1339\n",
            "121/157, train_loss: 0.1514\n",
            "122/157, train_loss: 0.1603\n",
            "123/157, train_loss: 0.1365\n",
            "124/157, train_loss: 0.1325\n",
            "125/157, train_loss: 0.1685\n",
            "126/157, train_loss: 0.1571\n",
            "127/157, train_loss: 0.1525\n",
            "128/157, train_loss: 0.1787\n",
            "129/157, train_loss: 0.1518\n",
            "130/157, train_loss: 0.1418\n",
            "131/157, train_loss: 0.1214\n",
            "132/157, train_loss: 0.1672\n",
            "133/157, train_loss: 0.1383\n",
            "134/157, train_loss: 0.1213\n",
            "135/157, train_loss: 0.1321\n",
            "136/157, train_loss: 0.1451\n",
            "137/157, train_loss: 0.1179\n",
            "138/157, train_loss: 0.1170\n",
            "139/157, train_loss: 0.1159\n",
            "140/157, train_loss: 0.1650\n",
            "141/157, train_loss: 0.1434\n",
            "142/157, train_loss: 0.1288\n",
            "143/157, train_loss: 0.1803\n",
            "144/157, train_loss: 0.1114\n",
            "145/157, train_loss: 0.1363\n",
            "146/157, train_loss: 0.1096\n",
            "147/157, train_loss: 0.1358\n",
            "148/157, train_loss: 0.1093\n",
            "149/157, train_loss: 0.1541\n",
            "150/157, train_loss: 0.1529\n",
            "151/157, train_loss: 0.1367\n",
            "152/157, train_loss: 0.1282\n",
            "153/157, train_loss: 0.1035\n",
            "154/157, train_loss: 0.1211\n",
            "155/157, train_loss: 0.1040\n",
            "156/157, train_loss: 0.1417\n",
            "157/157, train_loss: 0.1627\n",
            "158/157, train_loss: 0.1393\n",
            "epoch 2 average loss: 0.1978\n",
            "saved new best metric model\n",
            "current epoch: 2 current AUC: 0.9995 current accuracy: 0.9826 best AUC: 0.9826 at epoch: 2\n",
            "----------\n",
            "epoch 3/4\n",
            "1/157, train_loss: 0.1471\n",
            "2/157, train_loss: 0.1132\n",
            "3/157, train_loss: 0.1335\n",
            "4/157, train_loss: 0.1370\n",
            "5/157, train_loss: 0.1626\n",
            "6/157, train_loss: 0.1413\n",
            "7/157, train_loss: 0.1183\n",
            "8/157, train_loss: 0.1251\n",
            "9/157, train_loss: 0.1259\n",
            "10/157, train_loss: 0.1149\n",
            "11/157, train_loss: 0.1065\n",
            "12/157, train_loss: 0.1136\n",
            "13/157, train_loss: 0.1312\n",
            "14/157, train_loss: 0.1198\n",
            "15/157, train_loss: 0.1154\n",
            "16/157, train_loss: 0.1142\n",
            "17/157, train_loss: 0.0940\n",
            "18/157, train_loss: 0.1223\n",
            "19/157, train_loss: 0.1204\n",
            "20/157, train_loss: 0.1081\n",
            "21/157, train_loss: 0.1274\n",
            "22/157, train_loss: 0.1045\n",
            "23/157, train_loss: 0.1156\n",
            "24/157, train_loss: 0.1438\n",
            "25/157, train_loss: 0.1305\n",
            "26/157, train_loss: 0.1101\n",
            "27/157, train_loss: 0.1767\n",
            "28/157, train_loss: 0.1060\n",
            "29/157, train_loss: 0.1219\n",
            "30/157, train_loss: 0.0884\n",
            "31/157, train_loss: 0.1201\n",
            "32/157, train_loss: 0.1360\n",
            "33/157, train_loss: 0.1016\n",
            "34/157, train_loss: 0.1053\n",
            "35/157, train_loss: 0.1290\n",
            "36/157, train_loss: 0.1070\n",
            "37/157, train_loss: 0.1107\n",
            "38/157, train_loss: 0.1012\n",
            "39/157, train_loss: 0.0756\n",
            "40/157, train_loss: 0.1169\n",
            "41/157, train_loss: 0.0931\n",
            "42/157, train_loss: 0.1133\n",
            "43/157, train_loss: 0.1080\n",
            "44/157, train_loss: 0.1077\n",
            "45/157, train_loss: 0.1264\n",
            "46/157, train_loss: 0.1194\n",
            "47/157, train_loss: 0.1136\n",
            "48/157, train_loss: 0.1059\n",
            "49/157, train_loss: 0.1254\n",
            "50/157, train_loss: 0.0925\n",
            "51/157, train_loss: 0.0886\n",
            "52/157, train_loss: 0.1082\n",
            "53/157, train_loss: 0.0798\n",
            "54/157, train_loss: 0.1112\n",
            "55/157, train_loss: 0.0961\n",
            "56/157, train_loss: 0.0951\n",
            "57/157, train_loss: 0.1270\n",
            "58/157, train_loss: 0.1265\n",
            "59/157, train_loss: 0.0977\n",
            "60/157, train_loss: 0.1145\n",
            "61/157, train_loss: 0.0783\n",
            "62/157, train_loss: 0.0900\n",
            "63/157, train_loss: 0.0653\n",
            "64/157, train_loss: 0.0799\n",
            "65/157, train_loss: 0.0935\n",
            "66/157, train_loss: 0.1041\n",
            "67/157, train_loss: 0.0872\n",
            "68/157, train_loss: 0.1064\n",
            "69/157, train_loss: 0.0689\n",
            "70/157, train_loss: 0.1367\n",
            "71/157, train_loss: 0.1057\n",
            "72/157, train_loss: 0.1006\n",
            "73/157, train_loss: 0.0966\n",
            "74/157, train_loss: 0.0870\n",
            "75/157, train_loss: 0.0885\n",
            "76/157, train_loss: 0.1074\n",
            "77/157, train_loss: 0.0887\n",
            "78/157, train_loss: 0.1163\n",
            "79/157, train_loss: 0.1173\n",
            "80/157, train_loss: 0.0989\n",
            "81/157, train_loss: 0.0935\n",
            "82/157, train_loss: 0.0819\n",
            "83/157, train_loss: 0.0869\n",
            "84/157, train_loss: 0.0990\n",
            "85/157, train_loss: 0.1013\n",
            "86/157, train_loss: 0.1047\n",
            "87/157, train_loss: 0.0993\n",
            "88/157, train_loss: 0.0745\n",
            "89/157, train_loss: 0.0801\n",
            "90/157, train_loss: 0.0895\n",
            "91/157, train_loss: 0.0914\n",
            "92/157, train_loss: 0.0913\n",
            "93/157, train_loss: 0.0987\n",
            "94/157, train_loss: 0.0757\n",
            "95/157, train_loss: 0.1095\n",
            "96/157, train_loss: 0.1074\n",
            "97/157, train_loss: 0.0846\n",
            "98/157, train_loss: 0.1148\n",
            "99/157, train_loss: 0.0771\n",
            "100/157, train_loss: 0.0748\n",
            "101/157, train_loss: 0.0877\n",
            "102/157, train_loss: 0.0833\n",
            "103/157, train_loss: 0.0861\n",
            "104/157, train_loss: 0.0989\n",
            "105/157, train_loss: 0.0934\n",
            "106/157, train_loss: 0.1073\n",
            "107/157, train_loss: 0.0901\n",
            "108/157, train_loss: 0.0775\n",
            "109/157, train_loss: 0.0980\n",
            "110/157, train_loss: 0.0833\n",
            "111/157, train_loss: 0.0748\n",
            "112/157, train_loss: 0.0921\n",
            "113/157, train_loss: 0.0561\n",
            "114/157, train_loss: 0.1030\n",
            "115/157, train_loss: 0.0822\n",
            "116/157, train_loss: 0.0884\n",
            "117/157, train_loss: 0.0948\n",
            "118/157, train_loss: 0.0807\n",
            "119/157, train_loss: 0.0676\n",
            "120/157, train_loss: 0.0627\n",
            "121/157, train_loss: 0.0861\n",
            "122/157, train_loss: 0.0760\n",
            "123/157, train_loss: 0.0564\n",
            "124/157, train_loss: 0.1181\n",
            "125/157, train_loss: 0.0682\n",
            "126/157, train_loss: 0.0927\n",
            "127/157, train_loss: 0.0616\n",
            "128/157, train_loss: 0.0821\n",
            "129/157, train_loss: 0.0736\n",
            "130/157, train_loss: 0.0805\n",
            "131/157, train_loss: 0.0795\n",
            "132/157, train_loss: 0.0787\n",
            "133/157, train_loss: 0.0596\n",
            "134/157, train_loss: 0.0942\n",
            "135/157, train_loss: 0.0682\n",
            "136/157, train_loss: 0.0997\n",
            "137/157, train_loss: 0.0722\n",
            "138/157, train_loss: 0.1252\n",
            "139/157, train_loss: 0.0716\n",
            "140/157, train_loss: 0.0588\n",
            "141/157, train_loss: 0.0591\n",
            "142/157, train_loss: 0.0885\n",
            "143/157, train_loss: 0.0583\n",
            "144/157, train_loss: 0.0829\n",
            "145/157, train_loss: 0.0739\n",
            "146/157, train_loss: 0.0674\n",
            "147/157, train_loss: 0.0837\n",
            "148/157, train_loss: 0.0748\n",
            "149/157, train_loss: 0.0854\n",
            "150/157, train_loss: 0.0580\n",
            "151/157, train_loss: 0.1109\n",
            "152/157, train_loss: 0.0766\n",
            "153/157, train_loss: 0.0622\n",
            "154/157, train_loss: 0.0612\n",
            "155/157, train_loss: 0.0673\n",
            "156/157, train_loss: 0.0716\n",
            "157/157, train_loss: 0.0661\n",
            "158/157, train_loss: 0.2544\n",
            "epoch 3 average loss: 0.0982\n",
            "saved new best metric model\n",
            "current epoch: 3 current AUC: 0.9999 current accuracy: 0.9917 best AUC: 0.9917 at epoch: 3\n",
            "----------\n",
            "epoch 4/4\n",
            "1/157, train_loss: 0.0562\n",
            "2/157, train_loss: 0.0688\n",
            "3/157, train_loss: 0.0821\n",
            "4/157, train_loss: 0.0849\n",
            "5/157, train_loss: 0.0878\n",
            "6/157, train_loss: 0.0616\n",
            "7/157, train_loss: 0.0862\n",
            "8/157, train_loss: 0.0640\n",
            "9/157, train_loss: 0.0627\n",
            "10/157, train_loss: 0.0942\n",
            "11/157, train_loss: 0.0637\n",
            "12/157, train_loss: 0.0547\n",
            "13/157, train_loss: 0.0619\n",
            "14/157, train_loss: 0.0675\n",
            "15/157, train_loss: 0.0671\n",
            "16/157, train_loss: 0.0989\n",
            "17/157, train_loss: 0.0758\n",
            "18/157, train_loss: 0.0589\n",
            "19/157, train_loss: 0.0703\n",
            "20/157, train_loss: 0.0480\n",
            "21/157, train_loss: 0.0785\n",
            "22/157, train_loss: 0.0493\n",
            "23/157, train_loss: 0.0435\n",
            "24/157, train_loss: 0.0624\n",
            "25/157, train_loss: 0.0619\n",
            "26/157, train_loss: 0.0980\n",
            "27/157, train_loss: 0.0578\n",
            "28/157, train_loss: 0.0488\n",
            "29/157, train_loss: 0.0517\n",
            "30/157, train_loss: 0.0755\n",
            "31/157, train_loss: 0.0805\n",
            "32/157, train_loss: 0.0532\n",
            "33/157, train_loss: 0.0563\n",
            "34/157, train_loss: 0.0950\n",
            "35/157, train_loss: 0.0557\n",
            "36/157, train_loss: 0.0586\n",
            "37/157, train_loss: 0.0501\n",
            "38/157, train_loss: 0.0620\n",
            "39/157, train_loss: 0.0611\n",
            "40/157, train_loss: 0.0668\n",
            "41/157, train_loss: 0.0672\n",
            "42/157, train_loss: 0.0803\n",
            "43/157, train_loss: 0.0629\n",
            "44/157, train_loss: 0.0828\n",
            "45/157, train_loss: 0.0642\n",
            "46/157, train_loss: 0.0808\n",
            "47/157, train_loss: 0.0490\n",
            "48/157, train_loss: 0.0542\n",
            "49/157, train_loss: 0.0764\n",
            "50/157, train_loss: 0.0673\n",
            "51/157, train_loss: 0.0534\n",
            "52/157, train_loss: 0.0764\n",
            "53/157, train_loss: 0.0635\n",
            "54/157, train_loss: 0.0754\n",
            "55/157, train_loss: 0.0620\n",
            "56/157, train_loss: 0.0620\n",
            "57/157, train_loss: 0.0463\n",
            "58/157, train_loss: 0.0843\n",
            "59/157, train_loss: 0.0537\n",
            "60/157, train_loss: 0.0466\n",
            "61/157, train_loss: 0.0679\n",
            "62/157, train_loss: 0.0624\n",
            "63/157, train_loss: 0.0512\n",
            "64/157, train_loss: 0.0664\n",
            "65/157, train_loss: 0.0532\n",
            "66/157, train_loss: 0.0560\n",
            "67/157, train_loss: 0.0443\n",
            "68/157, train_loss: 0.0544\n",
            "69/157, train_loss: 0.0465\n",
            "70/157, train_loss: 0.0523\n",
            "71/157, train_loss: 0.0398\n",
            "72/157, train_loss: 0.0444\n",
            "73/157, train_loss: 0.0770\n",
            "74/157, train_loss: 0.0579\n",
            "75/157, train_loss: 0.0599\n",
            "76/157, train_loss: 0.0671\n",
            "77/157, train_loss: 0.0473\n",
            "78/157, train_loss: 0.0444\n",
            "79/157, train_loss: 0.0585\n",
            "80/157, train_loss: 0.0745\n",
            "81/157, train_loss: 0.0494\n",
            "82/157, train_loss: 0.0442\n",
            "83/157, train_loss: 0.0628\n",
            "84/157, train_loss: 0.0408\n",
            "85/157, train_loss: 0.0692\n",
            "86/157, train_loss: 0.0683\n",
            "87/157, train_loss: 0.0799\n",
            "88/157, train_loss: 0.0757\n",
            "89/157, train_loss: 0.0785\n",
            "90/157, train_loss: 0.0614\n",
            "91/157, train_loss: 0.0787\n",
            "92/157, train_loss: 0.0426\n",
            "93/157, train_loss: 0.0891\n",
            "94/157, train_loss: 0.0375\n",
            "95/157, train_loss: 0.0748\n",
            "96/157, train_loss: 0.0445\n",
            "97/157, train_loss: 0.0358\n",
            "98/157, train_loss: 0.0730\n",
            "99/157, train_loss: 0.0645\n",
            "100/157, train_loss: 0.0513\n",
            "101/157, train_loss: 0.0462\n",
            "102/157, train_loss: 0.0528\n",
            "103/157, train_loss: 0.0406\n",
            "104/157, train_loss: 0.0742\n",
            "105/157, train_loss: 0.0479\n",
            "106/157, train_loss: 0.0687\n",
            "107/157, train_loss: 0.0299\n",
            "108/157, train_loss: 0.0683\n",
            "109/157, train_loss: 0.0454\n",
            "110/157, train_loss: 0.0762\n",
            "111/157, train_loss: 0.0732\n",
            "112/157, train_loss: 0.0705\n",
            "113/157, train_loss: 0.0439\n",
            "114/157, train_loss: 0.0324\n",
            "115/157, train_loss: 0.0449\n",
            "116/157, train_loss: 0.0729\n",
            "117/157, train_loss: 0.0499\n",
            "118/157, train_loss: 0.0439\n",
            "119/157, train_loss: 0.0543\n",
            "120/157, train_loss: 0.0445\n",
            "121/157, train_loss: 0.0496\n",
            "122/157, train_loss: 0.0351\n",
            "123/157, train_loss: 0.0477\n",
            "124/157, train_loss: 0.0463\n",
            "125/157, train_loss: 0.0537\n",
            "126/157, train_loss: 0.0719\n",
            "127/157, train_loss: 0.0487\n",
            "128/157, train_loss: 0.0303\n",
            "129/157, train_loss: 0.0902\n",
            "130/157, train_loss: 0.0421\n",
            "131/157, train_loss: 0.0477\n",
            "132/157, train_loss: 0.0557\n",
            "133/157, train_loss: 0.0603\n",
            "134/157, train_loss: 0.0413\n",
            "135/157, train_loss: 0.0370\n",
            "136/157, train_loss: 0.0800\n",
            "137/157, train_loss: 0.0413\n",
            "138/157, train_loss: 0.0464\n",
            "139/157, train_loss: 0.0338\n",
            "140/157, train_loss: 0.0529\n",
            "141/157, train_loss: 0.0714\n",
            "142/157, train_loss: 0.0648\n",
            "143/157, train_loss: 0.0744\n",
            "144/157, train_loss: 0.0604\n",
            "145/157, train_loss: 0.0588\n",
            "146/157, train_loss: 0.0552\n",
            "147/157, train_loss: 0.0354\n",
            "148/157, train_loss: 0.0562\n",
            "149/157, train_loss: 0.0482\n",
            "150/157, train_loss: 0.0609\n",
            "151/157, train_loss: 0.0767\n",
            "152/157, train_loss: 0.0563\n",
            "153/157, train_loss: 0.0658\n",
            "154/157, train_loss: 0.0531\n",
            "155/157, train_loss: 0.0542\n",
            "156/157, train_loss: 0.0487\n",
            "157/157, train_loss: 0.0586\n",
            "158/157, train_loss: 0.0338\n",
            "epoch 4 average loss: 0.0599\n",
            "saved new best metric model\n",
            "current epoch: 4 current AUC: 0.9999 current accuracy: 0.9947 best AUC: 0.9947 at epoch: 4\n",
            "train completed, best_metric: 0.9947 at epoch: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model on test dataset"
      ],
      "metadata": {
        "id": "EMMRwJ0jLwh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_metric_model.pth'))\n",
        "model.eval()\n",
        "y_true = list()\n",
        "y_pred = list()\n",
        "with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())"
      ],
      "metadata": {
        "id": "L4TrH01iLsTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace2b536-f091-4ac8-8b5d-1dd8fdd04cd5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_metric_model.pth'))\n",
        "model.eval()\n",
        "y_true = list()\n",
        "y_pred = list()\n",
        "with torch.no_grad():\n",
        "    for test_data in test_loader:\n",
        "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
        "        pred = model(test_images).argmax(dim=1)\n",
        "        for i in range(len(pred)):\n",
        "            y_true.append(test_labels[i].item())\n",
        "            y_pred.append(pred[i].item())"
      ],
      "metadata": {
        "id": "4cBzARoqeZUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LTnfRuuSmaj",
        "outputId": "70ebb1e3-28b3-482f-b8bc-fa6db38a3fa5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   AbdomenCT     0.9915    0.9924    0.9919      1054\n",
            "   BreastMRI     0.9946    0.9892    0.9919       923\n",
            "         CXR     1.0000    0.9908    0.9954       979\n",
            "     ChestCT     0.9922    1.0000    0.9961      1019\n",
            "        Hand     0.9943    0.9962    0.9953      1056\n",
            "      HeadCT     0.9938    0.9969    0.9953       961\n",
            "\n",
            "    accuracy                         0.9943      5992\n",
            "   macro avg     0.9944    0.9942    0.9943      5992\n",
            "weighted avg     0.9943    0.9943    0.9943      5992\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   AbdomenCT     0.9915    0.9924    0.9919      1054\n",
            "   BreastMRI     0.9946    0.9892    0.9919       923\n",
            "         CXR     1.0000    0.9908    0.9954       979\n",
            "     ChestCT     0.9922    1.0000    0.9961      1019\n",
            "        Hand     0.9943    0.9962    0.9953      1056\n",
            "      HeadCT     0.9938    0.9969    0.9953       961\n",
            "\n",
            "    accuracy                         0.9943      5992\n",
            "   macro avg     0.9944    0.9942    0.9943      5992\n",
            "weighted avg     0.9943    0.9943    0.9943      5992\n",
            "\n"
          ]
        }
      ]
    }
  ]
}